{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender\n",
    "\n",
    "Investigating the effect of gender on bill-passing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import codecs\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "from matplotlib import gridspec\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download, load, and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download zipped dataset.\n",
    "url = 'http://congressionalbills.org/billfiles/bills93-114.zip'\n",
    "filename = 'bills93-114.csv'\n",
    "filepath = 'data/'+filename+'.zip'\n",
    "if not os.path.isfile(filepath):\n",
    "    with open(filepath, 'wb') as f:\n",
    "            f.write(urllib.request.urlopen(url).read())\n",
    "            \n",
    "# Load dataframe.\n",
    "with zipfile.ZipFile(filepath) as zf:\n",
    "    with zf.open(filename) as f:\n",
    "        old_df = pd.read_csv(f, sep=';', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEXT_COL = 'Title'\n",
    "BOOL_COLS = ['Party', 'Majority']\n",
    "CAT_COLS = ['Major']\n",
    "TGT_COLS = ['PLaw', 'Gender']\n",
    "ALL_COLS = [TEXT_COL]+BOOL_COLS+CAT_COLS+TGT_COLS\n",
    "\n",
    "## FEATURE PROCESSING\n",
    "# Drop 50k bills that have missing data in one of the cols.\n",
    "df = old_df[ALL_COLS].dropna()\n",
    "# Remove 8 non-party-affiated bills.\n",
    "df = df[df['Party'] != 328.0]\n",
    "df['Party'] = df['Party'].map(lambda k: {100.0: 1, 200.0: 0}[k])\n",
    "# Process categorical columns.\n",
    "df['Major'] = df['Major'].map(lambda k: 'm'+str(int(k)))\n",
    "# Fit tf-idf vectorizer on all data.\n",
    "vec = TfidfVectorizer(sublinear_tf=True, smooth_idf=False)\n",
    "vec.fit(df[TEXT_COL].values.reshape(-1))\n",
    "# Fit categorical encoder.\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(df[CAT_COLS])\n",
    "# Encode 1/0 cols as boolean.\n",
    "df[BOOL_COLS+TGT_COLS] = df[BOOL_COLS+TGT_COLS].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Helper functions\n",
    "\n",
    "def logistic(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def enc_bool(seq):\n",
    "    return 2 * seq.values - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_df(df):\n",
    "    avail_cols = set(df.keys())\n",
    "    bool_cols = list(filter(lambda c: c in avail_cols, BOOL_COLS))\n",
    "    cat_cols = list(filter(lambda c: c in avail_cols, CAT_COLS))\n",
    "    text_col = TEXT_COL if TEXT_COL in avail_cols else None\n",
    "\n",
    "    # get categorical and boolean features.\n",
    "    bool_dset = enc_bool(df[bool_cols]) # assume that we have some boolean cols at least.\n",
    "    cat_dset = enc.transform(df[cat_cols]).todense().A if len(cat_cols) else None\n",
    "    var_dset = np.concatenate([cat_dset, bool_dset], axis=1) if len(cat_cols) else bool_dset\n",
    "    sp_dset = sp.csr_matrix(var_dset)\n",
    "    \n",
    "    # get text features.\n",
    "    text_dset = vec.transform(df[text_col].values.reshape(-1)) if text_col else None\n",
    "    dset = sp.csr_matrix(sp.hstack([text_dset, sp_dset])) if text_col else sp_dset\n",
    "    \n",
    "    targets = [df[tgt_col].values.reshape(-1) for tgt_col in TGT_COLS]\n",
    "    return [dset, *targets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_probs(df):\n",
    "    plaw_xx = df[df['Gender']]['PLaw'].mean()\n",
    "    plaw_xy = df[~df['Gender']]['PLaw'].mean()\n",
    "    return plaw_xx, plaw_xy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Empirical Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of bill proposals, 8.053% were by women.\n",
      "Success rates: 0.028 (women), 0.043 (men)\n"
     ]
    }
   ],
   "source": [
    "perc_xx = 100 * df['Gender'].mean()\n",
    "plaw_xx, plaw_xy = get_probs(df)\n",
    "print('Of bill proposals, %.3f%% were by women.' % perc_xx)\n",
    "print('Success rates: %.3f (women), %.3f (men)' % (plaw_xx, plaw_xy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Is this explained by women {choosing harder topics, being in the wrong party}\n",
    "\n",
    "Answer: Nope, across most topic/party combinations, women continue to have roughly half the success rate of men. Interestingly, this is worse for democrat women than republican women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "967 10069\n",
      "Success rates: 0.054 (women), 0.096 (men)\n"
     ]
    }
   ],
   "source": [
    "rest_df = df[(df['Major'] == 'm21') & df['Party']]\n",
    "df_xx, df_xy = rest_df[rest_df['Gender']], rest_df[~rest_df['Gender']]\n",
    "print(len(df_xx), len(df_xy))\n",
    "plaw_xx, plaw_xy = df_xx['PLaw'].mean(), df_xy['PLaw'].mean()\n",
    "print('Success rates: %.3f (women), %.3f (men)' % (plaw_xx, plaw_xy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: What if we factor in the bill's title?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For bill $i$, let $x_i$ be a representation of the bill by `Title`, `Topic`, `Party`, and `Majority`. Furthermore, let $z_i$ be the gender of the proposer (1 for female, 0 for male), and $y_i$ be whether the bill became a law.\n",
    "\n",
    "To determine the effect of gender on bill-passing, we wish to compute the average log-ratio between the probability of the bill passing given gender=male vs gender=female. This is expressed by\n",
    "\n",
    "$$\\mathbb{E}_{x \\sim \\mathcal D}\\bigg[\\log\\dfrac{P(Y=1 \\mid X=x, Z=0)}{P(Y=1 \\mid X=x, Z=1)}\\bigg]$$\n",
    "\n",
    "where $\\mathcal D$ is the distribution over $X$, in this case simply the empirical distribution over the provided dataset.\n",
    "\n",
    "To compute $P(Y=1 \\mid X=x, Z=z)$, split into $\\dfrac{P(Y=1, Z=z \\mid X=x)}{P(Z=z \\mid X=x)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the model we need is for $P(Y, Z \\mid X)$.\n",
    "\n",
    "Alternate approach: compute the difference between modeled $P(Y \\mid X, Z)$ and $P(Y \\mid X)$?\n",
    "\n",
    "The relationship is $\\dfrac{P(Y \\mid X, Z)}{P(Y \\mid X)} = \\dfrac{P(Y, Z \\mid X)}{P(Y \\mid X)P(Z \\mid X)} = \\dfrac{P(Z \\mid X, Y)}{P(Z \\mid X)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the issue with simply setting up a linear model to compute $P(Y=1 \\mid X, Z)$? The issue is that the linear model will learn $P(X \\mid Z)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## For class balancing, subsample an even number of bills that did and did not become law.\n",
    "# df_p = df[df['PLaw'] == True]\n",
    "# df_n = df[df['PLaw'] == False].sample(5*len(df_p))\n",
    "# small_df = pd.concat([df_p, df_n])\n",
    "small_df = df.sample(40000) # alternative: simply subsample.\n",
    "\n",
    "## Also subsample by gender\n",
    "# df_xx = small_df[small_df['Gender'] == True]\n",
    "# df_xy = small_df[small_df['Gender'] == False].sample(2*len(df_xx))\n",
    "# small_df = pd.concat([df_xx, df_xy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train / dev set.\n",
    "train_df, dev_df = train_test_split(small_df, test_size=0.2)\n",
    "# Process data.\n",
    "trnX, trnY, trnZ = process_df(train_df)\n",
    "devX, devY, devZ = process_df(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.965, loss: 0.124\n"
     ]
    }
   ],
   "source": [
    "# Construct logistic regression on Y (PLaw).\n",
    "clsY = LogisticRegression(solver='lbfgs', max_iter=10000, C=3)\n",
    "clsY.predict_unnorm = lambda x: (x * clsY.coef_[0]) + clsY.intercept_[0]\n",
    "clsY.fit(trnX, trnY)\n",
    "\n",
    "# evaluate the model.\n",
    "pred_pr = clsY.predict_proba(devX)\n",
    "pred_y = clsY.predict(devX)\n",
    "acc = metrics.accuracy_score(devY, pred_y)\n",
    "loss = metrics.log_loss(devY, pred_pr)\n",
    "print('acc: %.3f, loss: %.3f' % (acc, loss))\n",
    "\n",
    "# Sanity check: evaluate alternate computation of output on devset\n",
    "Zs = clsY.predict_unnorm(devX)\n",
    "pred = (Zs > 0)\n",
    "assert np.abs((pred == devY).mean() - acc) < 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct logistic regression on Y (PLaw).\n",
    "clsZ = LogisticRegression(solver='lbfgs', max_iter=10000, C=3)\n",
    "clsZ.predict_unnorm = lambda x: (x * clsZ.coef_[0]) + clsZ.intercept_[0]\n",
    "clsZ.fit(trnX, trnY)\n",
    "\n",
    "# evaluate the model.\n",
    "pred_pr = clsY.predict_proba(devX)\n",
    "pred_y = clsY.predict(devX)\n",
    "acc = metrics.accuracy_score(devY, pred_y)\n",
    "loss = metrics.log_loss(devY, pred_pr)\n",
    "print('acc: %.3f, loss: %.3f' % (acc, loss))\n",
    "\n",
    "# Sanity check: evaluate alternate computation of output on devset\n",
    "Zs = clsY.predict_unnorm(devX)\n",
    "pred = (Zs > 0)\n",
    "assert np.abs((pred == devY).mean() - acc) < 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.04396989301719478\n"
     ]
    }
   ],
   "source": [
    "# Compute optimal weight on gender feature, having frozen other weights/features.\n",
    "Zs = cls.predict_unnorm(trnX)\n",
    "feat_gender = enc_bool(train_df['Gender'])\n",
    "\n",
    "w_gender = 0\n",
    "\n",
    "## run gradient descent only for the gender-weight.\n",
    "for eta in [10.0, 1.0, 0.1, 0.01]:\n",
    "    for _ in range(100):\n",
    "        w_gender += eta * np.mean((trnY - logistic(Zs + w_gender * feat_gender)) * feat_gender)\n",
    "\n",
    "print(w_gender)\n",
    "\n",
    "def without_gender(df):\n",
    "    X, _ = process_df(df.drop('Gender', axis=1))\n",
    "    return cls.predict_unnorm(X)\n",
    "\n",
    "def with_gender(df):\n",
    "    X, _ = process_df(df.drop('Gender', axis=1))\n",
    "    feat_gender = enc_bool(df['Gender'])\n",
    "    return cls.predict_unnorm(X) + w_gender * feat_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.963, loss: 0.131\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on devset\n",
    "Zs = without_gender(dev_df)\n",
    "Zs_gender = with_gender(dev_df)\n",
    "\n",
    "pred_pr = logistic(Zs_gender)\n",
    "pred_y = (Zs_gender > 0)\n",
    "acc = metrics.accuracy_score(devY, pred_y)\n",
    "loss = metrics.log_loss(devY, pred_pr)\n",
    "print('acc: %.3f, loss: %.3f' % (acc, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.033 0.041\n"
     ]
    }
   ],
   "source": [
    "mask = dev_df['Gender'].values.astype(bool)\n",
    "\n",
    "prob_XX = logistic(without_gender(dev_df[mask]))\n",
    "prob_XY = logistic(without_gender(dev_df[~mask]))\n",
    "print('%.3f %.3f' % (prob_XX.mean(), prob_XY.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With an independent linear expert, unk->female decreases prob by 0.963\n"
     ]
    }
   ],
   "source": [
    "prob_xx1 = prob_XX.mean()\n",
    "prob_xx2 = logistic(with_gender(dev_df[mask])).mean()\n",
    "print('With an independent linear expert, unk->female decreases prob by %.3f' % (prob_xx2/prob_xx1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
